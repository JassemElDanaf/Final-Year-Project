{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4116a5a2",
   "metadata": {},
   "source": [
    "# 01 — Prepare PV & Load (authoritative clean)\n",
    "This notebook:\n",
    "1) Robustly loads `data/interim/pv_5homes_10min.csv` and `data/interim/load_5homes_10min.csv`\n",
    "2) Detects timestamp column and numeric columns\n",
    "3) Aligns on **time only**\n",
    "4) Normalizes columns to `h1..hN`\n",
    "5) Detects/repairs unit mismatch (PV in kWh/10min vs Load in kW → multiply PV by 6)\n",
    "6) Writes cleaned artifacts to `data/processed/` and a quick meta report to `reports/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166a4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT = e:\\VPP\n",
      "PV_FILE  = e:\\VPP\\data\\interim\\pv_5homes_10min.csv\n",
      "LOAD_FILE= e:\\VPP\\data\\interim\\load_5homes_10min.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# silence pandas' noisy datetime warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*infer_datetime_format.*\")\n",
    "\n",
    "# ---- locate project root no matter where we run ----\n",
    "CWD = Path.cwd()\n",
    "ROOT = next((c for c in [CWD, CWD.parent, CWD.parent.parent] if (c / \"data\" / \"interim\").exists()), None)\n",
    "if ROOT is None:\n",
    "    raise FileNotFoundError(\"Could not find 'data/interim' from here.\")\n",
    "\n",
    "DATA_INTERIM  = ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED= ROOT / \"data\" / \"processed\"\n",
    "REPORTS       = ROOT / \"reports\"\n",
    "for p in [DATA_PROCESSED, REPORTS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PV_FILE   = DATA_INTERIM / \"pv_5homes_10min.csv\"\n",
    "LOAD_FILE = DATA_INTERIM / \"load_5homes_10min.csv\"\n",
    "FREQ      = \"10min\"\n",
    "\n",
    "print(\"ROOT =\", ROOT)\n",
    "print(\"PV_FILE  =\", PV_FILE)\n",
    "print(\"LOAD_FILE=\", LOAD_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f12a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numeric_timeindexed_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust CSV loader:\n",
    "      - auto-detect separator\n",
    "      - auto-detect a datetime column (>=90% parseable) → set as index\n",
    "      - coerce remaining columns to numeric (decimal comma tolerant)\n",
    "    Returns numeric-only DataFrame indexed by datetime.\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {path}\")\n",
    "    df_raw = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "    # detect datetime-like column\n",
    "    dt_col = None\n",
    "    for c in df_raw.columns:\n",
    "        parsed = pd.to_datetime(df_raw[c], errors=\"coerce\")\n",
    "        if parsed.notna().mean() >= 0.9:\n",
    "            dt_col = c\n",
    "            df_raw[c] = parsed\n",
    "            break\n",
    "    if dt_col is None:\n",
    "        raise ValueError(f\"{path.name}: no datetime-like column detected.\")\n",
    "\n",
    "    df = df_raw.set_index(dt_col).sort_index()\n",
    "\n",
    "    # numeric coercion; try decimal-comma fallback if needed\n",
    "    df_num = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    if df_num.select_dtypes(\"number\").empty and df.shape[1] > 0:\n",
    "        df_num = df.replace(\",\", \".\", regex=True).apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df_num = df_num.select_dtypes(\"number\")\n",
    "    if df_num.empty:\n",
    "        raise ValueError(f\"{path.name}: no numeric columns after parsing.\")\n",
    "    return df_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceebbeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                               h1      h2      h3      h4      h5\n",
       " Datetime (UTC)                                                   \n",
       " 2018-08-23 00:00:00+00:00  1.4553  0.8685  0.2131  1.3281  0.6848\n",
       " 2018-08-23 00:10:00+00:00  1.2215  0.7258  0.2074  1.0968  0.5842\n",
       " 2018-08-23 00:20:00+00:00  0.7083  0.4063  0.1484  0.6183  0.3586\n",
       " 2018-08-23 00:30:00+00:00  0.2100  0.1199  0.0822  0.2169  0.1486\n",
       " 2018-08-23 00:40:00+00:00  0.2501  0.0524  0.0092  0.1928  0.0619,\n",
       "                                h1      h2      h3      h4      h5\n",
       " Datetime (UTC)                                                   \n",
       " 2018-08-23 00:00:00+00:00  4.9506  4.8633  3.3314  3.0321  6.3395\n",
       " 2018-08-23 00:10:00+00:00  4.9671  7.6854  3.3686  2.9578  8.8531\n",
       " 2018-08-23 00:20:00+00:00  4.9438  2.8980  3.4492  2.9553  6.6892\n",
       " 2018-08-23 00:30:00+00:00  4.9768  6.7631  3.2522  3.0799  6.4424\n",
       " 2018-08-23 00:40:00+00:00  4.8692  4.7304  3.1914  3.2387  6.2083,\n",
       " ['h1', 'h2', 'h3', 'h4', 'h5'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_raw   = load_numeric_timeindexed_csv(PV_FILE)\n",
    "load_raw = load_numeric_timeindexed_csv(LOAD_FILE)\n",
    "\n",
    "# align on TIME ONLY (keep columns)\n",
    "common_idx = pv_raw.index.intersection(load_raw.index)\n",
    "if common_idx.empty:\n",
    "    raise ValueError(\"No overlapping timestamps between PV and Load.\")\n",
    "pv = pv_raw.loc[common_idx].sort_index()\n",
    "ld = load_raw.loc[common_idx].sort_index()\n",
    "\n",
    "# normalize to h1..hN\n",
    "def to_home_cols(cols, prefix):\n",
    "    mp = {}\n",
    "    for c in cols:\n",
    "        s = str(c)\n",
    "        if s.startswith(prefix):\n",
    "            num = s[len(prefix):]\n",
    "            if num.isdigit():\n",
    "                mp[c] = f\"h{int(num)}\"\n",
    "    return mp\n",
    "\n",
    "pv = pv.rename(columns=to_home_cols(pv.columns, \"pv_\"))\n",
    "ld = ld.rename(columns=to_home_cols(ld.columns, \"load_\"))\n",
    "\n",
    "# if names don't match, fall back to position mapping\n",
    "if pv.columns.intersection(ld.columns).empty:\n",
    "    n = min(pv.shape[1], ld.shape[1])\n",
    "    pv = pv.iloc[:, :n].copy()\n",
    "    ld = ld.iloc[:, :n].copy()\n",
    "    pv.columns = [f\"h{i+1}\" for i in range(n)]\n",
    "    ld.columns = [f\"h{i+1}\" for i in range(n)]\n",
    "\n",
    "homes = pv.columns.intersection(ld.columns).tolist()\n",
    "pv = pv[homes]\n",
    "ld = ld[homes]\n",
    "\n",
    "pv.head(), ld.head(), homes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a2067a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pv_med': 2.58225, 'load_med': 3.2796, 'x6_applied': False}\n"
     ]
    }
   ],
   "source": [
    "def pos_median(df: pd.DataFrame) -> float:\n",
    "    x = df[df > 0]\n",
    "    return float(x.median(numeric_only=True).median())\n",
    "\n",
    "pv_med, ld_med = pos_median(pv), pos_median(ld)\n",
    "apply_times6 = False\n",
    "if pd.notna(pv_med) and pd.notna(ld_med) and pv_med > 0 and ld_med > 0:\n",
    "    ratio = ld_med / pv_med\n",
    "    # typical: PV was energy per 10-min (kWh/slot) vs load power (kW)\n",
    "    if 5.0 <= ratio <= 7.5:\n",
    "        apply_times6 = True\n",
    "        pv = pv * 6.0  # convert PV to kW\n",
    "\n",
    "print({\"pv_med\": pv_med, \"load_med\": ld_med, \"x6_applied\": apply_times6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53efd449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote:\n",
      "   e:/VPP/data/processed/pv_kW_10min.csv\n",
      "   e:/VPP/data/processed/load_kW_10min.csv\n",
      "   e:/VPP/data/processed/surplus_kW_10min.csv\n",
      "   e:/VPP/reports/prepare_meta.txt\n"
     ]
    }
   ],
   "source": [
    "surplus = (pv - ld).fillna(0.0)\n",
    "\n",
    "pv_out   = DATA_PROCESSED / \"pv_kW_10min.csv\"\n",
    "ld_out   = DATA_PROCESSED / \"load_kW_10min.csv\"\n",
    "sup_out  = DATA_PROCESSED / \"surplus_kW_10min.csv\"\n",
    "meta_out = REPORTS / \"prepare_meta.txt\"\n",
    "\n",
    "pv.to_csv(pv_out)\n",
    "ld.to_csv(ld_out)\n",
    "surplus.to_csv(sup_out)\n",
    "\n",
    "with open(meta_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"01_prepare_pv_load — meta\\n\")\n",
    "    f.write(f\"rows={len(pv)} homes={len(homes)} freq={FREQ}\\n\")\n",
    "    f.write(f\"unit_fix_x6_applied={apply_times6}\\n\")\n",
    "    f.write(f\"timestamp_range={pv.index.min()} .. {pv.index.max()}\\n\")\n",
    "    f.write(f\"homes={homes}\\n\")\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"  \", pv_out.as_posix())\n",
    "print(\"  \", ld_out.as_posix())\n",
    "print(\"  \", sup_out.as_posix())\n",
    "print(\"  \", meta_out.as_posix())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
